{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T08:17:11.225037Z",
     "start_time": "2024-06-14T08:17:11.217176Z"
    },
    "id": "4cf0a253a113bf38"
   },
   "outputs": [],
   "source": [
    "# Importing the necessary libraries and data\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split,  GridSearchCV, KFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from yellowbrick.classifier import ROCAUC, ClassificationReport, ClassPredictionError, ConfusionMatrix\n",
    "\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# machine learning models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "#interpretml\n",
    "from interpret import show\n",
    "from interpret.glassbox._ebm._research import *\n",
    "from interpret.data import ClassHistogram\n",
    "from interpret.perf import ROC\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from interpret.blackbox import ShapKernel, LimeTabular, MorrisSensitivity\n",
    "\n",
    "from interpret.provider import InlineProvider\n",
    "from interpret import set_visualize_provider\n",
    "\n",
    "set_visualize_provider(InlineProvider())\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "# # Replace the Chinese fonts with the ones supported by your system.\n",
    "# plt.rcParams['axes.unicode_minus'] = False  # Used to display the negative sign normally\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CNUmS2RKEYLf"
   },
   "outputs": [],
   "source": [
    "work_dir = 'E:/Disk E/Grand Blue/Research studies/HDL_multiclass'\n",
    "os.chdir(work_dir)\n",
    "os.makedirs('./tables', exist_ok=True)\n",
    "os.makedirs('./images/png', exist_ok=True)\n",
    "os.makedirs('./images/pdf', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prim = pd.read_excel('data/TertileClass_Gensini_data.xlsx')\n",
    "print(df_prim['Gensini_tertile_label'].value_counts())\n",
    "df_prim.drop(['Gensini_total_Score', 'Gensini_tertile_label'], axis=1, inplace=True)\n",
    "df_prim.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iHobxTp4HCmG"
   },
   "outputs": [],
   "source": [
    "df = df_prim.copy()\n",
    "\n",
    "\n",
    "df.info()\n",
    "\n",
    "target_col ='Gensini_tertile'\n",
    "print('df: ', Counter(df[target_col]))\n",
    "\n",
    "# Define label \n",
    "# The sequential numerical codes are 0, 1, 2\n",
    "class_names = ['Low', 'Moderate', 'High']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 820
    },
    "id": "lm4dmEHnh6fb",
    "outputId": "74ddcbc6-c972-4985-dc36-3d31cb6209a6"
   },
   "outputs": [],
   "source": [
    "# Exploring the dataset\n",
    "# Target variable prediction (buggy for multicategorisation, only 2 categories shown)\n",
    "X = df.drop(target_col, axis=1)\n",
    "y = df[target_col] \n",
    "\n",
    "hist = ClassHistogram().explain_data(X, y, name=\"Full Data\")\n",
    "show(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_cols=[ 'age', 'TC', 'TG', 'HDL-C', 'LDL-C', 'HDL-2b', 'HDL-3' ]\n",
    "df_k = df.copy()\n",
    "df_k['Gensini_tertile'] = df_k ['Gensini_tertile'].replace( {0: 'Low', 1:'moderate', 2:'High'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phik_overview = df_k.phik_matrix(interval_cols=interval_cols)\n",
    "\n",
    "plot_correlation_matrix(phik_overview.values, x_labels=phik_overview.columns, y_labels=phik_overview.index, \n",
    "                        vmin=0, vmax=1, color_map='Greens', title=r'correlation $\\phi_K$', fontsize_factor=1.5,\n",
    "                        figsize=(30,30))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('images/png/correlation matrix.png', dpi=300)\n",
    "plt.savefig('images/pdf/correlation matrix.pdf', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_overview = df_k.significance_matrix(interval_cols=interval_cols)\n",
    "plot_correlation_matrix(significance_overview.values, \n",
    "                        x_labels=significance_overview.columns, \n",
    "                        y_labels=significance_overview.index, \n",
    "                        vmin=-5, vmax=5, title=\"Significance of the coefficients\", \n",
    "                        usetex=False, fontsize_factor=1.5, figsize=(30, 30))\n",
    "plt.savefig('images/png/Statistical significance.png', dpi=300)\n",
    "plt.savefig('images/pdf/Statistical significance.pdf', dpi=300)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_correlation, global_labels = df_k.global_phik(interval_cols=interval_cols)\n",
    "\n",
    "plot_correlation_matrix(global_correlation, \n",
    "                        x_labels=[''], y_labels=global_labels, \n",
    "                        vmin=0, vmax=1, figsize=(15,15),\n",
    "                        color_map=\"Greens\", title=r\"$g_k$\",\n",
    "                        fontsize_factor=1.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/png/Global correlation.png', dpi=300)\n",
    "plt.savefig('images/pdf/Global correlation.pdf', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_1 = \"HDL-2b\"\n",
    "var_2 = \"Gensini_tertile\"\n",
    "\n",
    "tmp_interval_cols = ['HDL-2b']\n",
    "\n",
    "outlier_signifs, binning_dict = df_k[[var_1, var_2]].outlier_significance_matrix(interval_cols=tmp_interval_cols, \n",
    "                                                                        retbins=True)\n",
    "\n",
    "zvalues = outlier_signifs.values\n",
    "xlabels = outlier_signifs.columns\n",
    "ylabels = outlier_signifs.index\n",
    "\n",
    "plot_correlation_matrix(zvalues, x_labels=xlabels, y_labels=ylabels, \n",
    "                        x_label=var_2,y_label=var_1,\n",
    "                        vmin=-5, vmax=5, title='outlier significance',\n",
    "                        identity_layout=False, fontsize_factor=1.2, \n",
    "                        figsize=(14, 10))\n",
    "\n",
    "plt.savefig(f'images/png/Outlier significance_{var_1}.png', dpi=300)\n",
    "plt.savefig(f'images/pdf/Global correlation_{var_1}.pdf', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_1 = \"HDL-3\"\n",
    "var_2 = \"Gensini_tertile\"\n",
    "\n",
    "tmp_interval_cols = ['HDL-3']\n",
    "\n",
    "outlier_signifs, binning_dict = df_k[[var_1, var_2]].outlier_significance_matrix(interval_cols=tmp_interval_cols, \n",
    "                                                                        retbins=True)\n",
    "\n",
    "zvalues = outlier_signifs.values\n",
    "xlabels = outlier_signifs.columns\n",
    "ylabels = outlier_signifs.index\n",
    "\n",
    "plot_correlation_matrix(zvalues, x_labels=xlabels, y_labels=ylabels, \n",
    "                        x_label=var_2,y_label=var_1,\n",
    "                        vmin=-5, vmax=5, title='outlier significance',\n",
    "                        identity_layout=False, fontsize_factor=1.2, \n",
    "                        figsize=(14, 10))\n",
    "\n",
    "plt.savefig(f'images/png/Outlier significance_{var_1}.png', dpi=300)\n",
    "plt.savefig(f'images/pdf/Global correlation_{var_1}.pdf', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resampling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def resample_data (df_res):\n",
    "#     \"\"\"\n",
    "#     Data resampling function\n",
    "#     \"\"\"\n",
    "#     X = df_res.drop(target_col, axis=1)\n",
    "#     y = df_res[target_col]\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         X, y, test_size=0.3, random_state=42, shuffle=True, stratify=y\n",
    "#     )\n",
    "#     print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "#     print('y_train: ', Counter(y_train))\n",
    "#     print('y_test: ', Counter(y_test))\n",
    "\n",
    "#     # define oversampling strategy\n",
    "#     over_strategy = {0: 270, 1: 270, 2: 450}\n",
    "#     ros = RandomOverSampler(sampling_strategy=over_strategy, random_state=42)\n",
    "#     X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "#     print('oversampling: ',X_train_ros.shape, y_train_ros.shape)\n",
    "#     print(Counter(y_train_ros))\n",
    "#     print('\\n')\n",
    "\n",
    "#     # define undersampling strategy   \n",
    "#     under_strategy = {0: 270, 1: 270, 2: 270}\n",
    "#     rus = RandomUnderSampler(sampling_strategy=under_strategy, random_state=42)\n",
    "#     X_train_res, y_train_res = rus.fit_resample(X_train_ros, y_train_ros) \n",
    "#     print('undersampling: ', X_train_res.shape, y_train_res.shape)\n",
    "#     print(Counter(y_train_res))\n",
    "\n",
    "#     # Merge training data and labels into a DataFrame\n",
    "#     train_df = pd.concat([X_train, y_train], axis=1)\n",
    "    \n",
    "#     return X_train_res, y_train_res, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training (function definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining multiple functions\n",
    "\n",
    "def model_tuning(clf, model_name, search_space):\n",
    "    \"\"\"\n",
    "    Function to perform model tuning\n",
    "    \"\"\"\n",
    "    X = df.drop(target_col, axis=1)\n",
    "    y = df[target_col]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, shuffle=True, stratify=y\n",
    "    )\n",
    "    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    print('y_train: ', Counter(y_train))\n",
    "    print('y_test: ', Counter(y_test))\n",
    "    \n",
    "    # Merge training data and labels into a DataFrame\n",
    "    train_df = pd.concat([X_train, y_train], axis=1)\n",
    "    \n",
    "       \n",
    "    clf_name = model_name\n",
    "    print('\\n')\n",
    "    print(clf_name) \n",
    "     \n",
    "    pipe = Pipeline([('clf', clf)])\n",
    "\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    scoring = {'F1_macro': metrics.make_scorer(metrics.f1_score, average='macro')}\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        pipe,\n",
    "        param_grid=search_space,\n",
    "        cv=kfold,\n",
    "        scoring=scoring,\n",
    "        refit='F1_macro',\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid_model = grid.fit(X_train, y_train)\n",
    "\n",
    "    print('\\nThe optimal parameters are：')\n",
    "    print(grid_model.best_params_)\n",
    "\n",
    "    print('\\nThe optimal parameters are：')\n",
    "    clf_best_model = grid_model.best_estimator_['clf']\n",
    "    print(clf_best_model)\n",
    "\n",
    "    return clf_best_model, X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# Function to create directories if they don't exist\n",
    "def create_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "# Function to save classification reports to an Excel file\n",
    "def save_classification_reports_to_excel(results, file_path):\n",
    "    with pd.ExcelWriter(file_path, engine='openpyxl') as writer:\n",
    "        for model_name, report in results.items():\n",
    "            df_report = pd.DataFrame(report).transpose()\n",
    "            df_report.to_excel(writer, sheet_name=model_name)\n",
    "\n",
    "# Function to create and save individual plots\n",
    "def save_individual_plots(clf_best_model, X_train, y_train, X_test, y_test, model_name, save_path):\n",
    "    # create_directory(save_path)\n",
    "    \n",
    "    # ROC AUC\n",
    "    fig, ax = plt.subplots()\n",
    "    visualizer_rocauc = ROCAUC(clf_best_model, classes=class_names, ax=ax)\n",
    "    visualizer_rocauc.fit(X_train, y_train)\n",
    "    visualizer_rocauc.score(X_test, y_test)\n",
    "    visualizer_rocauc.finalize()\n",
    "    plt.title('')\n",
    "    plt.savefig(f'{save_path}/png/{model_name.lower().replace(\" \", \"_\")}_roc_auc.png', dpi=300)\n",
    "    plt.savefig(f'{save_path}/pdf/{model_name.lower().replace(\" \", \"_\")}_roc_auc.pdf', dpi=300)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Classification Report\n",
    "    fig, ax = plt.subplots()\n",
    "    visualizer_class_report = ClassificationReport(clf_best_model, classes=class_names, support=True, ax=ax)\n",
    "    visualizer_class_report.fit(X_train, y_train)\n",
    "    visualizer_class_report.score(X_test, y_test)\n",
    "    visualizer_class_report.finalize()\n",
    "    plt.title('')\n",
    "    plt.savefig(f'{save_path}/png/{model_name.lower().replace(\" \", \"_\")}_class_report.png', dpi=300)\n",
    "    plt.savefig(f'{save_path}/pdf/{model_name.lower().replace(\" \", \"_\")}_class_report.pdf', dpi=300)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Prediction Error\n",
    "    fig, ax = plt.subplots()\n",
    "    visualizer_pred_error = ClassPredictionError(clf_best_model, classes=class_names, ax=ax)\n",
    "    visualizer_pred_error.fit(X_train, y_train)\n",
    "    visualizer_pred_error.score(X_test, y_test)\n",
    "    visualizer_pred_error.finalize()\n",
    "    plt.title('')\n",
    "    plt.savefig(f'{save_path}/png/{model_name.lower().replace(\" \", \"_\")}_pred_error.png', dpi=300)\n",
    "    plt.savefig(f'{save_path}/pdf/{model_name.lower().replace(\" \", \"_\")}_pred_error.pdf', dpi=300)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    fig, ax = plt.subplots()\n",
    "    visualizer_conf_matrix = ConfusionMatrix(clf_best_model, classes=class_names, ax=ax)\n",
    "    visualizer_conf_matrix.fit(X_train, y_train)\n",
    "    visualizer_conf_matrix.score(X_test, y_test)\n",
    "    visualizer_conf_matrix.finalize()\n",
    "    plt.title('')\n",
    "    plt.savefig(f'{save_path}/png/{model_name.lower().replace(\" \", \"_\")}_conf_matrix.png', dpi=300)\n",
    "    plt.savefig(f'{save_path}/pdf/{model_name.lower().replace(\" \", \"_\")}_conf_matrix.pdf', dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "# Function to create combined subplots\n",
    "def create_combined_subplot(fig_title, subplot_func):\n",
    "    num_models = len(models)\n",
    "    rows = (num_models + 1) // 2\n",
    "    fig, axes = plt.subplots(rows, 2, figsize=(12, 6 * rows), sharex=False, sharey=False)\n",
    "\n",
    "    for i, (clf, model_name, search_space) in enumerate(models):\n",
    "        ax = axes[i // 2, i % 2]\n",
    "        clf_best_model, X_train, X_test, y_train, y_test = model_tuning(clf, model_name, search_space)\n",
    "        subplot_func(clf_best_model, X_train, y_train, X_test, y_test, ax, model_name)\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    if num_models % 2 != 0:\n",
    "        fig.delaxes(axes[rows - 1, 1])\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(fig_title, y=1.02)\n",
    "    return fig\n",
    "\n",
    "# Function for ROC AUC\n",
    "def plot_rocauc(clf_best_model, X_train, y_train, X_test, y_test, ax, model_name):\n",
    "    visualizer_rocauc = ROCAUC(clf_best_model, classes=class_names, ax=ax)\n",
    "    visualizer_rocauc.fit(X_train, y_train)\n",
    "    visualizer_rocauc.score(X_test, y_test)\n",
    "    visualizer_rocauc.finalize()\n",
    "    ax.set_title(f'ROC AUC - {model_name}')\n",
    "\n",
    "# Function for Classification Report\n",
    "def plot_class_report(clf_best_model, X_train, y_train, X_test, y_test, ax, model_name):\n",
    "    visualizer_class_report = ClassificationReport(clf_best_model, classes=class_names, support=True, ax=ax)\n",
    "    visualizer_class_report.fit(X_train, y_train)\n",
    "    visualizer_class_report.score(X_test, y_test)\n",
    "    visualizer_class_report.finalize()\n",
    "    ax.set_title(f'Classification Report - {model_name}')\n",
    "\n",
    "# Function for Prediction Error\n",
    "def plot_pred_error(clf_best_model, X_train, y_train, X_test, y_test, ax, model_name):\n",
    "    visualizer_pred_error = ClassPredictionError(clf_best_model, classes=class_names, ax=ax)\n",
    "    visualizer_pred_error.fit(X_train, y_train)\n",
    "    visualizer_pred_error.score(X_test, y_test)\n",
    "    visualizer_pred_error.finalize()\n",
    "    ax.set_title(f'Prediction Error - {model_name}')\n",
    "\n",
    "# Function for Confusion Matrix\n",
    "def plot_conf_matrix(clf_best_model, X_train, y_train, X_test, y_test, ax, model_name):\n",
    "    visualizer_conf_matrix = ConfusionMatrix(clf_best_model, classes=class_names, ax=ax)\n",
    "    visualizer_conf_matrix.fit(X_train, y_train)\n",
    "    visualizer_conf_matrix.score(X_test, y_test)\n",
    "    visualizer_conf_matrix.finalize()\n",
    "    ax.set_title(f'Confusion Matrix - {model_name}')\n",
    "\n",
    "\n",
    "# New function to extract weighted avg metrics and plot heatmap\n",
    "def plot_weighted_avg_heatmap(results, save_path):\n",
    "    data = {\n",
    "        'Model': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1-score': []\n",
    "        # 'Support': []\n",
    "    }\n",
    "\n",
    "    for model_name, report in results.items():\n",
    "        weighted_avg = report['weighted avg']\n",
    "        data['Model'].append(model_name)\n",
    "        data['Precision'].append(weighted_avg['precision'])\n",
    "        data['Recall'].append(weighted_avg['recall'])\n",
    "        data['F1-score'].append(weighted_avg['f1-score'])\n",
    "        # data['Support'].append(weighted_avg['support'])\n",
    "\n",
    "    df_ave = pd.DataFrame(data)\n",
    "    df_ave.set_index('Model', inplace=True)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(df_ave, annot=True, cmap='YlOrRd', fmt='.3f')\n",
    "    # Note font colour set to black\n",
    "    # sns.heatmap(df_ave, annot=True, cmap='YlOrRd', fmt='.3f',annot_kws={\"color\": \"black\"})\n",
    "    # plt.title('Weighted Average Metrics for Different Models')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_path}/png/weighted_avg_heatmap.png', dpi=300)\n",
    "    plt.savefig(f'{save_path}/pdf/weighted_avg_heatmap.pdf', dpi=300)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpQMrIAhDa4y"
   },
   "source": [
    "# Initial model name reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:00:35.644835Z",
     "start_time": "2024-07-09T14:00:35.628535Z"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1720251396035,
     "user": {
      "displayName": "cha xiao",
      "userId": "16193505507115044478"
     },
     "user_tz": -480
    },
    "id": "cPrJR7ZFrlwz"
   },
   "outputs": [],
   "source": [
    "# Building the basic model\n",
    "# log_clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=42)\n",
    "\n",
    "\n",
    "# log_clf = LogisticRegression(random_state=42)\n",
    "# lasso_reg = Lasso(random_state=42)\n",
    "# elastic_net = ElasticNet(random_state=42)\n",
    "# random_forest_clf = RandomForestClassifier(random_state=42)\n",
    "# extra_trees_clf = ExtraTreesClassifier(random_state=42)\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "# dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# svm_clf = SVC(probability=True, random_state=42)\n",
    "# mlp_clf = MLPClassifier(max_iter=10000, random_state=42)\n",
    "\n",
    "\n",
    "# xgb_clf = XGBClassifier(nthread=-1, random_state=42)\n",
    "\n",
    "# ebm_clf = ExplainableBoostingClassifier(greedy_ratio=0.5, random_state=42)\n",
    "\n",
    "# # lightgbm for classification\n",
    "# lgb_clf = LGBMClassifier(random_state=42)\n",
    "\n",
    "# # catboost for classification\n",
    "# catb_clf = CatBoostClassifier(verbose=0, n_estimators=100)\n",
    "# catb_clf = CatBoostClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # XGBoost： compute sample weights for handling imbalanced data\n",
    "# Merge training data and labels into a DataFrame\n",
    "# train_df = pd.concat([X_train, y_train], axis=1)\n",
    "# sample_weights = compute_sample_weight(\n",
    "#     class_weight='balanced',\n",
    "#     y=train_df[target_col] #provide your own target name\n",
    "# )\n",
    "\n",
    "# xgb_clf = XGBClassifier(nthread=-1, random_state=42,  sample_weight=sample_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model hyperparameter configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# logistic Model Tuning parameters\n",
    "search_space_log = [\n",
    "    {\n",
    "              # 'clf__solver' : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "        #       'clf__penalty' : ['l2'],\n",
    "        #       'clf__C' : [0.001,0.01,0.1,1,10,100,1000]\n",
    "              # 'clf__C' : [0.01,0.1,1,10]\n",
    "    }\n",
    "]\n",
    "\n",
    "# xgboost Model Tuning parameters\n",
    "# Define our search space for grid search\n",
    "search_space_xgb = [\n",
    "    {\n",
    "        # 'clf__n_estimators': [5000],\n",
    "        # 'clf__learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "        # 'clf__max_depth': [3, 4,5],\n",
    "        # 'clf__colsample_bytree': [i / 10.0 for i in range(1, 3)],\n",
    "        # 'clf__gamma': [i / 10.0 for i in range(3)],\n",
    "        # 'fs__score_func': [chi2],\n",
    "        # 'fs__k': [10]\n",
    "    }\n",
    "]\n",
    "\n",
    "# RandomForestClassifier Model tuning\n",
    "search_space_rf = [\n",
    "    {\n",
    "    # 'clf__bootstrap': [True],\n",
    "    # 'clf__max_depth': [80, 90, 100, 110],\n",
    "    # 'clf__max_features': [2, 3],\n",
    "    # 'clf__min_samples_leaf': [3, 4, 5],\n",
    "    # 'clf__min_samples_split': [8, 10, 12],\n",
    "    # 'clf__n_estimators': [100, 200, 300, 1000]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# EBM Model tuning\n",
    "# Define our search space for grid search\n",
    "search_space_ebm = [\n",
    "    {\n",
    "        # \"clf__validation_size\": [0.1, 0.15, 0.2],\n",
    "        # \"clf__greedy_ratio\": [0.0, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 4.0]\n",
    "       # \"clf__greedy_ratio\": [ 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 4.0]\n",
    "\n",
    "    }\n",
    "]\n",
    "\n",
    "# search_space_ebm = [\n",
    "#     {   \"clf__max_bins\": [1024, 4096, 16384, 65536],\n",
    "#      # \"clf__max_interaction_bins\": [8, 16, 32, 64, 128, 256],\n",
    "#      # \"clf__outer_bags\": [50],\n",
    "#      # \"clf__learning_rate\": [0.02, 0.01, 0.005, 0.0025],\n",
    "#      \"clf__greedy_ratio\": [0.0, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 4.0],\n",
    "#      # \"clf__cyclic_progress\": [0.0, 0.5, 1.0],\n",
    "#      # \"clf__smoothing_rounds\": [0, 50, 100, 200, 500, 1000, 2000, 4000],\n",
    "#      \"clf__max_leaves\": [3, 4]  \n",
    "#     }\n",
    "# ]\n",
    "\n",
    "\n",
    "# LightGBM Model tuning\n",
    "# Define our search space for grid search\n",
    "# search_space_lgb = [\n",
    "#     {\n",
    "#         # 'clf__n_estimators': [5000],\n",
    "#         # 'clf__learning_rate': [0.1],\n",
    "#         # 'clf__max_depth': range(1,11),\n",
    "#         # 'clf__boosting_type': ['gbdt', 'dart', 'goss']\n",
    "\n",
    "\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "\n",
    "# CatBoost Model tuning\n",
    "# Define our search space for grid search\n",
    "# search_space_catb = [\n",
    "#     {\n",
    "#         # 'clf__n_estimators': [10, 50, 100, 500, 1000, 5000],\n",
    "#         # 'clf__learning_rate': [0.1],\n",
    "#         # 'clf__max_depth': range(1,11)\n",
    "\n",
    "\n",
    "#     }\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison Type Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List of models and their corresponding search spaces\n",
    "# models = [\n",
    "#     (LogisticRegression(multi_class='multinomial', solver='lbfgs',penalty= 'l2', random_state=42), 'Logistic Regression', search_space_log),\n",
    "#     (XGBClassifier(nthread=-1, max_depth=4,  random_state=42), 'XGBoost', search_space_xgb),\n",
    "#     (ExplainableBoostingClassifier(greedy_ratio=0.5, random_state=42), 'Explainable Boosting Machine', search_space_ebm),\n",
    "#     (RandomForestClassifier(max_features = 3, random_state=42), 'Random Forest', search_space_rf)\n",
    "    \n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models and their corresponding search spaces\n",
    "models = [\n",
    "    (LogisticRegression(C=1, multi_class='multinomial', solver='lbfgs',penalty= 'l2', random_state=42), 'Logistic Regression', search_space_log),\n",
    "    (XGBClassifier(nthread=-1, max_depth=3,  random_state=42), 'XGBoost', search_space_xgb),\n",
    "    (ExplainableBoostingClassifier(greedy_ratio=4.0, random_state=42), 'Explainable Boosting Machine', search_space_ebm),\n",
    "    (RandomForestClassifier(max_depth=80, random_state=42), 'Random Forest', search_space_rf)\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning model training (calling functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------call function --------------------\n",
    "\n",
    "# Set seaborn theme to \"darkgrid\"\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "\n",
    "classification_reports = {}\n",
    "for clf, model_name, search_space in models:\n",
    "    # Save individual plots for each model\n",
    "    clf_best_model, X_train, X_test, y_train, y_test = model_tuning(clf, model_name, search_space)\n",
    "    save_individual_plots(clf_best_model, X_train, y_train, X_test, y_test, model_name, './images')\n",
    "    \n",
    "    # Generate classification report\n",
    "    y_pred = clf_best_model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, target_names=class_names)\n",
    "    classification_reports[model_name] = report\n",
    "\n",
    "# Save all classification reports to a single Excel file\n",
    "save_classification_reports_to_excel(classification_reports, './tables/classification_reports.xlsx')\n",
    "\n",
    "\n",
    "# Plot and save the heatmap of weighted average metrics\n",
    "plot_weighted_avg_heatmap(classification_reports, './images')\n",
    "\n",
    "\n",
    "# Create and save combined ROC AUC subplot\n",
    "fig_rocauc = create_combined_subplot('Combined ROC AUC', plot_rocauc)\n",
    "fig_rocauc.savefig('./images/png/combined_rocauc.png', dpi=300)\n",
    "fig_rocauc.savefig('./images/pdf/combined_rocauc.pdf', dpi=300)\n",
    "\n",
    "# Create and save combined Classification Report subplot\n",
    "fig_class_report = create_combined_subplot('Combined Classification Report', plot_class_report)\n",
    "fig_class_report.savefig('./images/png/combined_class_report.png', dpi=300)\n",
    "fig_class_report.savefig('./images/pdf/combined_class_report.pdf', dpi=300)\n",
    "\n",
    "# Create and save combined Prediction Error subplot\n",
    "fig_pred_error = create_combined_subplot('Combined Prediction Error', plot_pred_error)\n",
    "fig_pred_error.savefig('./images/png/combined_pred_error.png', dpi=300)\n",
    "fig_pred_error.savefig('./images/pdf/combined_pred_error.pdf', dpi=300)\n",
    "\n",
    "# Create and save combined Confusion Matrix subplot\n",
    "fig_conf_matrix = create_combined_subplot('Combined Confusion Matrix', plot_conf_matrix)\n",
    "fig_conf_matrix.savefig('./images/png/combined_conf_matrix.png', dpi=300)\n",
    "fig_conf_matrix.savefig('./images/pdf/combined_conf_matrix.pdf', dpi=300)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EBM model interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_prim.copy()\n",
    "\n",
    "# Converting Numeric Values to Labeled for EBM Modelling\n",
    "columns_to_replace = [ 'hypertension', 'diabetes', 'stroke', 'kidney disease','Thyroid Dysfunction', 'COPD']  \n",
    "# Replace with the column name list you want to replace\n",
    "\n",
    "# Use a dictionary to specify the value to replace\n",
    "replacement_dict = {1: 'Yes', 0: 'No'}\n",
    "\n",
    "# Application Replacement\n",
    "df2 [columns_to_replace] = df2 [columns_to_replace].replace(replacement_dict)\n",
    "\n",
    "df2 ['sex'] = df2 ['sex'].replace( {1: 'Male', 0: 'Female'})\n",
    "df2 ['Gensini_tertile'] = df2 ['Gensini_tertile'].replace({0: 'Low', 1:'moderate', 2:'High'})\n",
    "df2 .head()\n",
    "# print(set(df2 [target_col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.drop(target_col, axis=1)\n",
    "y = df2[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, shuffle=True, stratify=y\n",
    ")\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "print('y_train: ', Counter(y_train))\n",
    "print('y_test: ', Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "id": "f9e99a28",
    "outputId": "948d2dca-42ab-47f5-9a0e-d120217085dd"
   },
   "outputs": [],
   "source": [
    "# Training the Explainable Boosting Machine (EBM)\n",
    "ebm = ExplainableBoostingClassifier(greedy_ratio=4.0, random_state=42 )\n",
    "ebm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DwVy7lB0pk5o",
    "outputId": "db347cc0-dadb-4e93-f19e-a61addf8a51d"
   },
   "outputs": [],
   "source": [
    "ebm.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm_global = ebm.explain_global(name='EBM')\n",
    "show(ebm_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom colours\n",
    "# custom_colors = {'Low': 'green', 'Moderate': 'blue', 'High': 'orange'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 820
    },
    "id": "a56d6cba",
    "outputId": "8141632a-e213-4afb-83e6-0ae167b709b3"
   },
   "outputs": [],
   "source": [
    "# Global Explanations - explaining the entire model behavior.\n",
    "ebm_global = ebm.explain_global(name='EBM')\n",
    "show(ebm_global)\n",
    "\n",
    "\n",
    "# Save each chart in the global explanation to the ‘images’ directory on the disk.\n",
    "for index, value in enumerate(ebm.term_names_):\n",
    "    plotly_fig = ebm_global.visualize(index)\n",
    "    # plotly_fig.write_image(f\"images/fig_{value}.png\", engine=\"kaleido\")\n",
    "    \n",
    "    # # Custom colours\n",
    "    # colors = {\n",
    "    #     'mild': '#9fc377',    \n",
    "    #     'moderate': '#0272a2', \n",
    "    #     'severe': '#ca0b03',   \n",
    "    #     'Distribution': '#ff7f0e' \n",
    "    # }\n",
    "\n",
    "    # line_width = 3  # Set the line width\n",
    "    \n",
    "    # # Modify legend colour (alternate code)\n",
    "    # for trace in plotly_fig['data']:\n",
    "    #     if 'name' in trace:\n",
    "    #         class_name = trace['name']\n",
    "    #         if 'line' in trace:\n",
    "    #             trace['line']['color'] = colors.get(class_name, '#000000')  # Set the colour, default is black\n",
    "    #             trace['line']['width'] = line_width  # Set the line width\n",
    "    #         elif 'marker' in trace:\n",
    "    #             trace['marker']['color'] = colors.get(class_name, '#000000')  # Set the colour, default is black\n",
    "    #             trace['marker']['line']['width'] = line_width  # Set the line width\n",
    "\n",
    "    \n",
    "    # Save as PNG，300 dpi\n",
    "    plotly_fig.write_image(f\"images/png/fig_{value}.png\", format=\"png\", scale=3, engine=\"kaleido\")\n",
    "    # Save as PDF，300 dpi\n",
    "    plotly_fig.write_image(f\"images/pdf/fig_{value}.pdf\", format=\"pdf\", scale=3, engine=\"kaleido\")\n",
    "\n",
    "print('All images saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining global graph functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_combined_plots(ebm_global, variables, list_var, scale=3):\n",
    "    \"\"\"\n",
    "    Generate graphs of multiple variables and combine them into subgraphs of n rows and 1 column\n",
    "\n",
    "    parameter:\n",
    "        ebm_global: The object that generates the diagram should contain the visualize method\n",
    "        variables: List with variable names\n",
    "        list_var: List of all variable names\n",
    "        scale: Scale of saved images\n",
    "        output_path: Path to save the image\n",
    "    \"\"\"\n",
    "    image_files = []\n",
    "    \n",
    "    for var in variables:\n",
    "        index = list_var.index(var)\n",
    "        \n",
    "        # Generate graph\n",
    "        plotly_fig = ebm_global.visualize(index)\n",
    "        \n",
    "        # Saving a single image\n",
    "        image_path = f\"images/png/fig_{var}.png\"\n",
    "        plotly_fig.write_image(image_path, format=\"png\", scale=scale, engine=\"kaleido\")\n",
    "        image_files.append(image_path)\n",
    "    \n",
    "    num_vars = len(variables)\n",
    "    fig, axs = plt.subplots(num_vars, 1, figsize=(8, 6*num_vars))  # Adjust figsize as needed\n",
    "\n",
    "    if num_vars == 1:\n",
    "        axs = [axs]  # Ensure axs is iterable\n",
    "\n",
    "    for i, image_file in enumerate(image_files):\n",
    "        img = mpimg.imread(image_file)\n",
    "        axs[i].imshow(img)\n",
    "        axs[i].axis('off')  # Hide the axes\n",
    "        axs[i].set_title(variables[i])\n",
    "    \n",
    "    # Adjust the layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Generate file name\n",
    "    combined_name = \"_\".join(variables)\n",
    "    \n",
    "    # Save as PNG，300 dpi\n",
    "    plt.savefig(f\"images/png/combined_fig_{combined_name}.png\", format=\"png\", dpi=300)\n",
    "    # Save as PDF，300 dpi\n",
    "    plt.savefig(f\"images/pdf/combined_fig_{combined_name}.pdf\", format=\"pdf\", dpi=300)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a combination chart\n",
    "ebm_global = ebm.explain_global(name='EBM')\n",
    "list_var = ebm.term_names_\n",
    "\n",
    "# Calling a function\n",
    "save_combined_plots(ebm_global, ['HDL-2b', 'HDL-3'], list_var)\n",
    "save_combined_plots(ebm_global, ['LDL-C', 'TC'], list_var)\n",
    "save_combined_plots(ebm_global, ['HDL-C', 'TG'], list_var)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other results output of EBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary graph\n",
    "ebm_explanation = ebm.explain_global()\n",
    "plotly_fig = ebm_explanation.visualize()\n",
    "\n",
    "# Save as PNG，300 dpi\n",
    "plotly_fig.write_image(\"images/png/fig_summary.png\", format=\"png\", scale=3, engine=\"kaleido\")\n",
    "# Save as PDF，300 dpi\n",
    "plotly_fig.write_image(\"images/pdf/fig_summary.pdf\", format=\"pdf\", scale=3, engine=\"kaleido\")\n",
    "print('summary images saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_export_dataframe(data, filename):\n",
    "    # Create a DataFrame containing the data\n",
    "    df_in = pd.DataFrame(data)\n",
    "    \n",
    "    # Sort the 'Importance' column in reverse order and reset the index\n",
    "    df_in = df_in.sort_values(by='Importance', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Keep 3 decimal places in the 'Importance' column and generate a new column\n",
    "    df_in['Importance value'] = df_in['Importance'].round(3)\n",
    "    \n",
    "    # Count the number of commas in each cell in the first column and add 1\n",
    "    df_in[\"Number of elements\"] = df_in.iloc[:, 0].apply(lambda x: str(x).count(',') + 1)\n",
    "\n",
    "    # Print data frame\n",
    "    print(df_in.head())\n",
    "        \n",
    "    #Writing DataFrame to Excel File\n",
    "    df_in.to_excel(filename, index=False)\n",
    "    print(f\"\\nResults have been written to {filename}\")\n",
    "    return df_in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Debugging Code\n",
    "# import plotly.graph_objects as go\n",
    "\n",
    "# fig = go.Figure(data=go.Bar(y=[2, 3, 1]))\n",
    "# fig.write_image(\"images/fig1.png\", engine=\"kaleido\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling a function\n",
    "importances = ebm.term_importances()\n",
    "names = ebm.term_names_\n",
    "\n",
    "# Calling common functions to create and export DataFrame\n",
    "data = {'Term Name': names, 'Importance': importances}\n",
    "df_m1 = create_and_export_dataframe(data, 'tables/term_importances.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set drawing style\n",
    "sns.set()\n",
    "\n",
    "# Create a drawing\n",
    "plt.figure(figsize=(18, 16))\n",
    "barplot = sns.barplot(\n",
    "    x='Importance value', \n",
    "    y='Term Name', \n",
    "    data=df_m1, \n",
    "    orient='h',\n",
    "    order=df_m1.sort_values('Importance value', ascending=False)['Term Name']\n",
    ")\n",
    "\n",
    "\n",
    " # Add value labels\n",
    "for p in barplot.patches:\n",
    "    barplot.annotate(\n",
    "        format(p.get_width(), '.3f'),  # Take three decimal places\n",
    "        (p.get_width(), p.get_y() + p.get_height() / 2.), \n",
    "        ha = 'left', \n",
    "        va = 'center',\n",
    "        xytext = (5, 0), \n",
    "        textcoords = 'offset points'\n",
    "    )\n",
    "\n",
    "\n",
    "plt.title('Global Term/Feature Importances')\n",
    "plt.xlabel('Mean Absolute Score (Weighted)')\n",
    "plt.ylabel('')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/png/barplot_summary.png', format='png', dpi=300)\n",
    "plt.savefig('images/pdf/barplot_summary.pdf', format='pdf', dpi=300)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two variable sets\n",
    "group1 = ['TC', 'TG', 'LDL-C', 'HDL-C']\n",
    "group2 = ['HDL-2b', 'HDL-3']\n",
    "\n",
    "# Generate all possible permutations and combinations, each of which \n",
    "# contains at least one variable from group1 and one variable from group2\n",
    "combinations = []\n",
    "\n",
    "for i in range(1, len(group1) + 1):\n",
    "    for j in range(1, len(group2) + 1):\n",
    "        for combo1 in itertools.combinations(group1, i):\n",
    "            for combo2 in itertools.combinations(group2, j):\n",
    "                combinations.append(list(combo1) + list(combo2))\n",
    "\n",
    "# Initialize my_global_exp\n",
    "my_global_exp = None\n",
    "\n",
    "five_feature_group = ['TC', 'TG', 'LDL-C','HDL-2b', 'HDL-3']\n",
    "all_other_terms = [term for term in ebm.term_names_ if term not in five_feature_group]\n",
    "all_terms_group = [term for term in ebm.term_names_]\n",
    "\n",
    "# Calculate the importances of each combination and update my_global_exp\n",
    "for combo in combinations:\n",
    "    if my_global_exp is None:\n",
    "        my_global_exp = append_group_importance(combo, ebm, X_train)\n",
    "        \n",
    "    else:\n",
    "        my_global_exp = append_group_importance(combo, ebm, X_train, global_exp=my_global_exp)\n",
    "\n",
    "\n",
    "my_global_exp = append_group_importance(group1, ebm, X_train, global_exp=my_global_exp)\n",
    "my_global_exp = append_group_importance(group2, ebm, X_train, global_exp=my_global_exp)\n",
    "my_global_exp = append_group_importance(all_other_terms, ebm, X_train, global_exp=my_global_exp,group_name=\"all_other_terms_excluding_TC_TG_LDL-C_HDL-2b_HDL-3\")\n",
    "my_global_exp = append_group_importance(all_terms_group, ebm, X_train, global_exp=my_global_exp,group_name=\"all_terms\")\n",
    "\n",
    "\n",
    "# Show the final result\n",
    "show(my_global_exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_imp = combinations+[group1]+[group2]+ [all_other_terms] +[all_terms_group]\n",
    "\n",
    "my_dict = get_group_and_individual_importances(list_imp, ebm, X_train)\n",
    "# for key in my_dict:\n",
    "#     print(f\"Term: {key} - Importance: {my_dict[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the importance of the combinations\n",
    "my_dict = get_group_and_individual_importances(list_imp,\n",
    "                                               ebm, X_train)\n",
    "\n",
    "# Call the general function to create and export a DataFrame\n",
    "data2 = {'Term': list(my_dict.keys()), 'Importance': list(my_dict.values())}\n",
    "df_m2 = create_and_export_dataframe(data2, 'tables/group_importances.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the rows with the maximum and second maximum \"Number of elements\" values\n",
    "max_idx = df_m2['Number of elements'].idxmax()\n",
    "second_max_idx = df_m2['Number of elements'].drop(max_idx).idxmax()\n",
    "\n",
    "# Modify the \"Term\" column\n",
    "df_m2.at[max_idx, 'Term'] = 'all_terms'\n",
    "df_m2.at[second_max_idx, 'Term'] = 'all_other_terms_excluding_TC_TG_LDL-C_HDL-2b_HDL-3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Number of elements\n",
    "grouped_data = df_m2.groupby(\"Number of elements\")\n",
    "\n",
    "# # Plot bar charts for each group\n",
    "# for group, group_data in grouped_data:\n",
    "#     # Sort by Importance value in descending order and take the top 3\n",
    "#     top3_data = group_data.nlargest(3, 'Importance value')\n",
    "\n",
    "#     # Create the plot\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     barplot = sns.barplot(\n",
    "#         x='Importance value', \n",
    "#         y=df_m2.columns[0], \n",
    "#         data=top3_data, \n",
    "#         orient='h',\n",
    "#         order=top3_data.sort_values('Importance value', ascending=False)[df_m2.columns[0]]\n",
    "#     )\n",
    "\n",
    "#     # Add value labels\n",
    "#     for p in barplot.patches:\n",
    "#         barplot.annotate(\n",
    "#             format(p.get_width(), '.3f'),  # Keep three decimal places\n",
    "#             (p.get_width(), p.get_y() + p.get_height() / 2.), \n",
    "#             ha = 'left', \n",
    "#             va = 'center',\n",
    "#             xytext = (5, 0), \n",
    "#             textcoords = 'offset points'\n",
    "#         )\n",
    "\n",
    "#     # Set the title\n",
    "#     plt.title(f'Number of elements in the group: {group}')\n",
    "#     plt.xlabel('Mean Absolute Score (Weighted)')\n",
    "#     plt.ylabel(df_m2.columns[0])\n",
    "\n",
    "#     # Save the plot as PNG and PDF formats\n",
    "#     plt.tight_layout()\n",
    "#     # plt.subplots_adjust(top=0.9, bottom=0.1, left=0.1, right=0.9)\n",
    "#     plt.savefig(f'images/png/barplot_group_{group}.png', format='png', dpi=300)\n",
    "#     plt.savefig(f'images/pdf/barplot_group_{group}.pdf', format='pdf', dpi=300)\n",
    "\n",
    "#     # Show the plot\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 4-row, 2-column subplot\n",
    "fig, axes = plt.subplots(4, 2, figsize=(16, 18))\n",
    "\n",
    "# Iterate through the groups and plot bar charts\n",
    "for (group, group_data), ax in zip(grouped_data, axes.flatten()):\n",
    "    # Sort by Importance value in descending order and take the top 3\n",
    "    top3_data = group_data.nlargest(3, 'Importance value')\n",
    "\n",
    "    # Create the bar chart\n",
    "    barplot = sns.barplot(\n",
    "        x='Importance value', \n",
    "        y=df_m2.columns[0], \n",
    "        data=top3_data, \n",
    "        orient='h',\n",
    "        order=top3_data.sort_values('Importance value', ascending=False)[df_m2.columns[0]],\n",
    "        ax=ax,\n",
    "        width=0.5\n",
    "    )\n",
    "\n",
    "    # Add value labels\n",
    "    for p in barplot.patches:\n",
    "        barplot.annotate(\n",
    "            format(p.get_width(), '.3f'),  # Keep three decimal places\n",
    "            (p.get_width(), p.get_y() + p.get_height() / 2.), \n",
    "            ha='left', \n",
    "            va='center',\n",
    "            xytext=(5, 0), \n",
    "            textcoords='offset points'\n",
    "        )\n",
    "\n",
    "    # Set title and labels\n",
    "    ax.set_title(f'Number of elements in the group: {group}', fontsize=14)\n",
    "    ax.set_xlabel('Mean Absolute Score (Weighted)', fontsize=12)\n",
    "    ax.set_ylabel('')\n",
    "    # ax.set_yticklabels(ax.get_yticklabels(), fontsize=10, rotation=45, ha=\"right\")  # Rotate y-axis labels\n",
    "\n",
    "# Adjust layout to avoid overlap\n",
    "plt.tight_layout()\n",
    "# plt.subplots_adjust(top=0.9, bottom=0.1, left=0.05, right=0.95, hspace=0.4, wspace=0.3)\n",
    "\n",
    "# Save the plot as PNG and PDF formats\n",
    "plt.savefig('images/png/barplot_groups.png', format='png', dpi=300)\n",
    "plt.savefig('images/pdf/barplot_groups.pdf', format='pdf', dpi=300)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 820
    },
    "editable": true,
    "id": "320912cc",
    "outputId": "ad182ead-96ff-47bc-caac-c1f39e2ca5f3",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Local Explanations: explaining individual predictions\n",
    "ebm_local = ebm.explain_local(X_test[:80], y_test[:80], name='EBM')\n",
    "show(ebm_local)\n",
    "\n",
    "# Save the explanation plot for the 0th data point in Local Explanations\n",
    "plotly_fig_local = ebm_local.visualize(1)\n",
    "\n",
    "# # Custom colors\n",
    "# colors = {\n",
    "#     'mild': '#9fc377',    # Green\n",
    "#     'moderate': '#0272a2', # Blue\n",
    "#     'severe': '#ca0b03',   # Red    \n",
    "# }\n",
    "\n",
    "# # Modify legend colors (backup code)\n",
    "# for trace in plotly_fig_local['data']:\n",
    "#     if 'name' in trace:\n",
    "#         class_name = trace['name']\n",
    "#         trace['marker']['color'] = colors.get(class_name, '#000000')  # Set color, default to black\n",
    "\n",
    "# Save as PNG, 300 dpi\n",
    "plotly_fig_local.write_image(\"images/png/fig_local.png\", format=\"png\", scale=3, engine=\"kaleido\")\n",
    "\n",
    "# Note encoding bug: The 0, 1, 2 in the image need to be checked against the dropdown menu for specific values, \n",
    "# and text should be modified in PDF before taking a screenshot to Save as PNG\n",
    "\n",
    "# Save as PDF, 300 dpi\n",
    "plotly_fig_local.write_image(\"images/pdf/fig_local.pdf\", format=\"pdf\", scale=3, engine=\"kaleido\")\n",
    "print('Local Explanations images saved.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ebm_local.data(1)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the underlying data for the selected cases used in local visualization explanations\n",
    "\n",
    "# Extract feature names, scores, and values\n",
    "feature_names = data['names'] + data['extra']['names']\n",
    "scores = np.array(data['scores'] + data['extra']['scores'])\n",
    "values = data['values'] + data['extra']['values']\n",
    "\n",
    "# Create a DataFrame\n",
    "df_local = pd.DataFrame(scores, index=feature_names, columns=data['meta']['label_names'])\n",
    "df_local['values'] = values\n",
    "\n",
    "# Write to an Excel file\n",
    "df_local.to_excel('tables/feature_scores_local_explanations.xlsx')\n",
    "\n",
    "print(\"Data has been written.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
