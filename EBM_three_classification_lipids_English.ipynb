{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T08:17:11.225037Z",
     "start_time": "2024-06-14T08:17:11.217176Z"
    },
    "id": "4cf0a253a113bf38"
   },
   "outputs": [],
   "source": [
    "# Importing the necessary libraries and data\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split,  GridSearchCV, KFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from yellowbrick.classifier import ROCAUC, ClassificationReport, ClassPredictionError, ConfusionMatrix\n",
    "\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# machine learning models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "#interpretml\n",
    "from interpret import show\n",
    "from interpret.glassbox._ebm._research import *\n",
    "from interpret.data import ClassHistogram\n",
    "from interpret.perf import ROC\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from interpret.blackbox import ShapKernel, LimeTabular, MorrisSensitivity\n",
    "\n",
    "from interpret.provider import InlineProvider\n",
    "from interpret import set_visualize_provider\n",
    "\n",
    "set_visualize_provider(InlineProvider())\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "# # Replace the Chinese fonts with the ones supported by your system.\n",
    "# plt.rcParams['axes.unicode_minus'] = False  # Used to display the negative sign normally\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CNUmS2RKEYLf"
   },
   "outputs": [],
   "source": [
    "work_dir = 'E:/Disk E/Grand Blue/Research studies/HDL_multiclass'\n",
    "os.chdir(work_dir)\n",
    "os.makedirs('./tables_lipid', exist_ok=True)\n",
    "os.makedirs('./images_lipid/png', exist_ok=True)\n",
    "os.makedirs('./images_lipid/pdf', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prim = pd.read_excel('data/TertileClass_Gensini_data.xlsx')\n",
    "print(df_prim['Gensini_tertile_label'].value_counts())\n",
    "# Remove redundant columns+ 'HDL-2b','HDL-3'\n",
    "df_prim.drop(['Gensini_total_Score', 'Gensini_tertile_label', 'HDL-2b','HDL-3'], axis=1, inplace=True)\n",
    "df_prim.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iHobxTp4HCmG"
   },
   "outputs": [],
   "source": [
    "df = df_prim.copy()\n",
    "\n",
    "df.info()\n",
    "\n",
    "target_col ='Gensini_tertile'\n",
    "print('df: ', Counter(df[target_col]))\n",
    "\n",
    "# Define label \n",
    "# The sequential numerical codes are 0, 1, 2\n",
    "class_names = ['Low', 'Moderate', 'High']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training (function definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining multiple functions\n",
    "\n",
    "def model_tuning(clf, model_name, search_space):\n",
    "    \"\"\"\n",
    "    Function to perform model tuning\n",
    "    \"\"\"\n",
    "    X = df.drop(target_col, axis=1)\n",
    "    y = df[target_col]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, shuffle=True, stratify=y\n",
    "    )\n",
    "    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    print('y_train: ', Counter(y_train))\n",
    "    print('y_test: ', Counter(y_test))\n",
    "    \n",
    "    # Merge training data and labels into a DataFrame\n",
    "    train_df = pd.concat([X_train, y_train], axis=1)\n",
    "    \n",
    "       \n",
    "    clf_name = model_name\n",
    "    print('\\n')\n",
    "    print(clf_name) \n",
    "     \n",
    "    pipe = Pipeline([('clf', clf)])\n",
    "\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    scoring = {'F1_macro': metrics.make_scorer(metrics.f1_score, average='macro')}\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        pipe,\n",
    "        param_grid=search_space,\n",
    "        cv=kfold,\n",
    "        scoring=scoring,\n",
    "        refit='F1_macro',\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid_model = grid.fit(X_train, y_train)\n",
    "\n",
    "    print('\\nThe optimal parameters are：')\n",
    "    print(grid_model.best_params_)\n",
    "\n",
    "    print('\\nThe optimal parameters are：')\n",
    "    clf_best_model = grid_model.best_estimator_['clf']\n",
    "    print(clf_best_model)\n",
    "\n",
    "    return clf_best_model, X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# Function to create directories if they don't exist\n",
    "def create_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "# Function to save classification reports to an Excel file\n",
    "def save_classification_reports_to_excel(results, file_path):\n",
    "    with pd.ExcelWriter(file_path, engine='openpyxl') as writer:\n",
    "        for model_name, report in results.items():\n",
    "            df_report = pd.DataFrame(report).transpose()\n",
    "            df_report.to_excel(writer, sheet_name=model_name)\n",
    "\n",
    "# Function to create and save individual plots\n",
    "def save_individual_plots(clf_best_model, X_train, y_train, X_test, y_test, model_name, save_path):\n",
    "    # create_directory(save_path)\n",
    "    \n",
    "    # ROC AUC\n",
    "    fig, ax = plt.subplots()\n",
    "    visualizer_rocauc = ROCAUC(clf_best_model, classes=class_names, ax=ax)\n",
    "    visualizer_rocauc.fit(X_train, y_train)\n",
    "    visualizer_rocauc.score(X_test, y_test)\n",
    "    visualizer_rocauc.finalize()\n",
    "    plt.title('')\n",
    "    plt.savefig(f'{save_path}/png/{model_name.lower().replace(\" \", \"_\")}_roc_auc.png', dpi=300)\n",
    "    plt.savefig(f'{save_path}/pdf/{model_name.lower().replace(\" \", \"_\")}_roc_auc.pdf', dpi=300)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Classification Report\n",
    "    fig, ax = plt.subplots()\n",
    "    visualizer_class_report = ClassificationReport(clf_best_model, classes=class_names, support=True, ax=ax)\n",
    "    visualizer_class_report.fit(X_train, y_train)\n",
    "    visualizer_class_report.score(X_test, y_test)\n",
    "    visualizer_class_report.finalize()\n",
    "    plt.title('')\n",
    "    plt.savefig(f'{save_path}/png/{model_name.lower().replace(\" \", \"_\")}_class_report.png', dpi=300)\n",
    "    plt.savefig(f'{save_path}/pdf/{model_name.lower().replace(\" \", \"_\")}_class_report.pdf', dpi=300)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Prediction Error\n",
    "    fig, ax = plt.subplots()\n",
    "    visualizer_pred_error = ClassPredictionError(clf_best_model, classes=class_names, ax=ax)\n",
    "    visualizer_pred_error.fit(X_train, y_train)\n",
    "    visualizer_pred_error.score(X_test, y_test)\n",
    "    visualizer_pred_error.finalize()\n",
    "    plt.title('')\n",
    "    plt.savefig(f'{save_path}/png/{model_name.lower().replace(\" \", \"_\")}_pred_error.png', dpi=300)\n",
    "    plt.savefig(f'{save_path}/pdf/{model_name.lower().replace(\" \", \"_\")}_pred_error.pdf', dpi=300)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    fig, ax = plt.subplots()\n",
    "    visualizer_conf_matrix = ConfusionMatrix(clf_best_model, classes=class_names, ax=ax)\n",
    "    visualizer_conf_matrix.fit(X_train, y_train)\n",
    "    visualizer_conf_matrix.score(X_test, y_test)\n",
    "    visualizer_conf_matrix.finalize()\n",
    "    plt.title('')\n",
    "    plt.savefig(f'{save_path}/png/{model_name.lower().replace(\" \", \"_\")}_conf_matrix.png', dpi=300)\n",
    "    plt.savefig(f'{save_path}/pdf/{model_name.lower().replace(\" \", \"_\")}_conf_matrix.pdf', dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "# Function to create combined subplots\n",
    "def create_combined_subplot(fig_title, subplot_func):\n",
    "    num_models = len(models)\n",
    "    rows = (num_models + 1) // 2\n",
    "    fig, axes = plt.subplots(rows, 2, figsize=(12, 6 * rows), sharex=False, sharey=False)\n",
    "\n",
    "    for i, (clf, model_name, search_space) in enumerate(models):\n",
    "        ax = axes[i // 2, i % 2]\n",
    "        clf_best_model, X_train, X_test, y_train, y_test = model_tuning(clf, model_name, search_space)\n",
    "        subplot_func(clf_best_model, X_train, y_train, X_test, y_test, ax, model_name)\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    if num_models % 2 != 0:\n",
    "        fig.delaxes(axes[rows - 1, 1])\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(fig_title, y=1.02)\n",
    "    return fig\n",
    "\n",
    "# Function for ROC AUC\n",
    "def plot_rocauc(clf_best_model, X_train, y_train, X_test, y_test, ax, model_name):\n",
    "    visualizer_rocauc = ROCAUC(clf_best_model, classes=class_names, ax=ax)\n",
    "    visualizer_rocauc.fit(X_train, y_train)\n",
    "    visualizer_rocauc.score(X_test, y_test)\n",
    "    visualizer_rocauc.finalize()\n",
    "    ax.set_title(f'ROC AUC - {model_name}')\n",
    "\n",
    "# Function for Classification Report\n",
    "def plot_class_report(clf_best_model, X_train, y_train, X_test, y_test, ax, model_name):\n",
    "    visualizer_class_report = ClassificationReport(clf_best_model, classes=class_names, support=True, ax=ax)\n",
    "    visualizer_class_report.fit(X_train, y_train)\n",
    "    visualizer_class_report.score(X_test, y_test)\n",
    "    visualizer_class_report.finalize()\n",
    "    ax.set_title(f'Classification Report - {model_name}')\n",
    "\n",
    "# Function for Prediction Error\n",
    "def plot_pred_error(clf_best_model, X_train, y_train, X_test, y_test, ax, model_name):\n",
    "    visualizer_pred_error = ClassPredictionError(clf_best_model, classes=class_names, ax=ax)\n",
    "    visualizer_pred_error.fit(X_train, y_train)\n",
    "    visualizer_pred_error.score(X_test, y_test)\n",
    "    visualizer_pred_error.finalize()\n",
    "    ax.set_title(f'Prediction Error - {model_name}')\n",
    "\n",
    "# Function for Confusion Matrix\n",
    "def plot_conf_matrix(clf_best_model, X_train, y_train, X_test, y_test, ax, model_name):\n",
    "    visualizer_conf_matrix = ConfusionMatrix(clf_best_model, classes=class_names, ax=ax)\n",
    "    visualizer_conf_matrix.fit(X_train, y_train)\n",
    "    visualizer_conf_matrix.score(X_test, y_test)\n",
    "    visualizer_conf_matrix.finalize()\n",
    "    ax.set_title(f'Confusion Matrix - {model_name}')\n",
    "\n",
    "\n",
    "# New function to extract weighted avg metrics and plot heatmap\n",
    "def plot_weighted_avg_heatmap(results, save_path):\n",
    "    data = {\n",
    "        'Model': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1-score': []\n",
    "        # 'Support': []\n",
    "    }\n",
    "\n",
    "    for model_name, report in results.items():\n",
    "        weighted_avg = report['weighted avg']\n",
    "        data['Model'].append(model_name)\n",
    "        data['Precision'].append(weighted_avg['precision'])\n",
    "        data['Recall'].append(weighted_avg['recall'])\n",
    "        data['F1-score'].append(weighted_avg['f1-score'])\n",
    "        # data['Support'].append(weighted_avg['support'])\n",
    "\n",
    "    df_ave = pd.DataFrame(data)\n",
    "    df_ave.set_index('Model', inplace=True)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(df_ave, annot=True, cmap='YlOrRd', fmt='.3f')\n",
    "    # Note font colour set to black\n",
    "    # sns.heatmap(df_ave, annot=True, cmap='YlOrRd', fmt='.3f',annot_kws={\"color\": \"black\"})\n",
    "    # plt.title('Weighted Average Metrics for Different Models')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_path}/png/weighted_avg_heatmap.png', dpi=300)\n",
    "    plt.savefig(f'{save_path}/pdf/weighted_avg_heatmap.pdf', dpi=300)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpQMrIAhDa4y"
   },
   "source": [
    "# Initial model name reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:00:35.644835Z",
     "start_time": "2024-07-09T14:00:35.628535Z"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1720251396035,
     "user": {
      "displayName": "cha xiao",
      "userId": "16193505507115044478"
     },
     "user_tz": -480
    },
    "id": "cPrJR7ZFrlwz"
   },
   "outputs": [],
   "source": [
    "# Building the basic model\n",
    "# log_clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=42)\n",
    "\n",
    "\n",
    "# log_clf = LogisticRegression(random_state=42)\n",
    "# lasso_reg = Lasso(random_state=42)\n",
    "# elastic_net = ElasticNet(random_state=42)\n",
    "# random_forest_clf = RandomForestClassifier(random_state=42)\n",
    "# extra_trees_clf = ExtraTreesClassifier(random_state=42)\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "# dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# svm_clf = SVC(probability=True, random_state=42)\n",
    "# mlp_clf = MLPClassifier(max_iter=10000, random_state=42)\n",
    "\n",
    "\n",
    "# xgb_clf = XGBClassifier(nthread=-1, random_state=42)\n",
    "\n",
    "# ebm_clf = ExplainableBoostingClassifier(greedy_ratio=0.5, random_state=42)\n",
    "\n",
    "# # lightgbm for classification\n",
    "# lgb_clf = LGBMClassifier(random_state=42)\n",
    "\n",
    "# # catboost for classification\n",
    "# catb_clf = CatBoostClassifier(verbose=0, n_estimators=100)\n",
    "# catb_clf = CatBoostClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model hyperparameter configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# logistic Model Tuning parameters\n",
    "search_space_log = [\n",
    "    {\n",
    "        #       'clf__solver' : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "        #       'clf__penalty' : ['l2'],\n",
    "        #       'clf__C' : [0.001,0.01,0.1,1,10,100,1000]\n",
    "    }\n",
    "]\n",
    "\n",
    "# xgboost Model Tuning parameters\n",
    "# Define our search space for grid search\n",
    "search_space_xgb = [\n",
    "    {\n",
    "        # 'clf__n_estimators': [5000],\n",
    "        # 'clf__learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "        # 'clf__max_depth': [3, 4,5],\n",
    "        # 'clf__colsample_bytree': [i / 10.0 for i in range(1, 3)],\n",
    "        # 'clf__gamma': [i / 10.0 for i in range(3)],\n",
    "        # 'fs__score_func': [chi2],\n",
    "        # 'fs__k': [10]\n",
    "    }\n",
    "]\n",
    "\n",
    "# RandomForestClassifier Model tuning\n",
    "search_space_rf = [\n",
    "    {\n",
    "    # 'clf__bootstrap': [True],\n",
    "    # 'clf__max_depth': [80, 90, 100, 110],\n",
    "    # 'clf__max_features': [2, 3],\n",
    "    # 'clf__min_samples_leaf': [3, 4, 5],\n",
    "    # 'clf__min_samples_split': [8, 10, 12],\n",
    "    # 'clf__n_estimators': [100, 200, 300, 1000]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# EBM Model tuning\n",
    "# Define our search space for grid search\n",
    "search_space_ebm = [\n",
    "    {\n",
    "        # \"clf__learning_rate\": [0.001, 0.005, 0.01, 0.03],\n",
    "        # \"clf__interactions\": [5, 10, 15],\n",
    "        # \"clf__max_interaction_bins\": [10, 15, 20],\n",
    "        # \"clf__max_rounds\": [5000, 10000, 15000, 20000],\n",
    "        # \"clf__min_samples_leaf\": [2, 3, 5],\n",
    "        # \"clf__max_leaves\": [3, 5, 10],\n",
    "\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# LightGBM Model tuning\n",
    "# Define our search space for grid search\n",
    "search_space_lgb = [\n",
    "    {\n",
    "        # 'clf__n_estimators': [5000],\n",
    "        # 'clf__learning_rate': [0.1],\n",
    "        # 'clf__max_depth': range(1,11),\n",
    "        # 'clf__boosting_type': ['gbdt', 'dart', 'goss']\n",
    "\n",
    "\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# CatBoost Model tuning\n",
    "# Define our search space for grid search\n",
    "search_space_catb = [\n",
    "    {\n",
    "        # 'clf__n_estimators': [10, 50, 100, 500, 1000, 5000],\n",
    "        # 'clf__learning_rate': [0.1],\n",
    "        # 'clf__max_depth': range(1,11)\n",
    "\n",
    "\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EBMModel tuning\n",
    "# # Define our search space for grid search\n",
    "# search_space_ebm = [\n",
    "#     {   \"clf__max_bins\": [1024, 4096, 16384, 65536],\n",
    "#      # \"clf__max_interaction_bins\": [8, 16, 32, 64, 128, 256],\n",
    "#      # \"clf__outer_bags\": [50],\n",
    "#      # \"clf__learning_rate\": [0.02, 0.01, 0.005, 0.0025],\n",
    "#      \"clf__greedy_ratio\": [0.0, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 4.0],\n",
    "#      # \"clf__cyclic_progress\": [0.0, 0.5, 1.0],\n",
    "#      # \"clf__smoothing_rounds\": [0, 50, 100, 200, 500, 1000, 2000, 4000],\n",
    "#      \"clf__max_leaves\": [3, 4]  \n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# model_tuning(ebm_clf, 'Explainable Boosting Machine', search_space_ebm )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison Type Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List of models and their corresponding search spaces\n",
    "# models = [\n",
    "#     (LogisticRegression(multi_class='multinomial', solver='lbfgs',penalty= 'l2', random_state=42), 'Logistic Regression', search_space_log),\n",
    "#     (XGBClassifier(nthread=-1, max_depth=4,  random_state=42), 'XGBoost', search_space_xgb),\n",
    "#     (ExplainableBoostingClassifier(greedy_ratio=0.5, random_state=42), 'Explainable Boosting Machine', search_space_ebm),\n",
    "#     (RandomForestClassifier(max_features = 3, random_state=42), 'Random Forest', search_space_rf)\n",
    "    \n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models and their corresponding search spaces\n",
    "models = [\n",
    "    (LogisticRegression(C=1, multi_class='multinomial', solver='lbfgs',penalty= 'l2', random_state=42), 'Logistic Regression', search_space_log),\n",
    "    (XGBClassifier(nthread=-1, max_depth=3,  random_state=42), 'XGBoost', search_space_xgb),\n",
    "    (ExplainableBoostingClassifier(greedy_ratio=4.0, random_state=42), 'Explainable Boosting Machine', search_space_ebm),\n",
    "    (RandomForestClassifier( max_depth=80, random_state=42), 'Random Forest', search_space_rf)\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning model training (calling functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------call function --------------------\n",
    "\n",
    "# Set seaborn theme to \"darkgrid\"\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "\n",
    "classification_reports = {}\n",
    "for clf, model_name, search_space in models:\n",
    "    # Save individual plots for each model\n",
    "    clf_best_model, X_train, X_test, y_train, y_test = model_tuning(clf, model_name, search_space)\n",
    "    save_individual_plots(clf_best_model, X_train, y_train, X_test, y_test, model_name, './images_lipid')\n",
    "    \n",
    "    # Generate classification report\n",
    "    y_pred = clf_best_model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, target_names=class_names)\n",
    "    classification_reports[model_name] = report\n",
    "\n",
    "# Save all classification reports to a single Excel file\n",
    "save_classification_reports_to_excel(classification_reports, './tables_lipid/classification_reports.xlsx')\n",
    "\n",
    "\n",
    "# Plot and save the heatmap of weighted average metrics\n",
    "plot_weighted_avg_heatmap(classification_reports, './images_lipid')\n",
    "\n",
    "\n",
    "# Create and save combined ROC AUC subplot\n",
    "fig_rocauc = create_combined_subplot('Combined ROC AUC', plot_rocauc)\n",
    "fig_rocauc.savefig('./images_lipid/png/combined_rocauc_lipid.png', dpi=300)\n",
    "fig_rocauc.savefig('./images_lipid/pdf/combined_rocauc_lipid.pdf', dpi=300)\n",
    "\n",
    "# Create and save combined Classification Report subplot\n",
    "fig_class_report = create_combined_subplot('Combined Classification Report', plot_class_report)\n",
    "fig_class_report.savefig('./images_lipid/png/combined_class_report_lipid.png', dpi=300)\n",
    "fig_class_report.savefig('./images_lipid/pdf/combined_class_report_lipid.pdf', dpi=300)\n",
    "\n",
    "# Create and save combined Prediction Error subplot\n",
    "fig_pred_error = create_combined_subplot('Combined Prediction Error', plot_pred_error)\n",
    "fig_pred_error.savefig('./images_lipid/png/combined_pred_error_lipid.png', dpi=300)\n",
    "fig_pred_error.savefig('./images_lipid/pdf/combined_pred_error_lipid.pdf', dpi=300)\n",
    "\n",
    "# Create and save combined Confusion Matrix subplot\n",
    "fig_conf_matrix = create_combined_subplot('Combined Confusion Matrix', plot_conf_matrix)\n",
    "fig_conf_matrix.savefig('./images_lipid/png/combined_conf_matrix_lipid.png', dpi=300)\n",
    "fig_conf_matrix.savefig('./images_lipid/pdf/combined_conf_matrix_lipid.pdf', dpi=300)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
